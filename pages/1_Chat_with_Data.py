# pages/1_Chat_with_Data.py
import streamlit as st
import pandas as pd
from pandasai import SmartDataframe # Or SmartDatalake if we evolve to it
# Assuming pandasai is installed and accessible.
# The specific LLM class (GooglePalm or GoogleGenerativeAI) is encapsulated in get_llm()
from app.core.llm_config import get_llm
from app.core.db_connector import get_db_engine # Import the DB engine function

st.set_page_config(layout="wide", page_title="Chat with Your Accounting Data")

st.title("ğŸ“Š ä¸æ‚¨çš„ä¼šè®¡æ•°æ®å¯¹è¯")
st.markdown("""
åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æå‡ºå…³äºæ‚¨ä¼šè®¡æ•°æ®çš„é—®é¢˜ã€‚
**è¯·æ³¨æ„:** å¦‚æœæ•°æ®åº“è¿æ¥å¤±è´¥æˆ–è¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ­¤åº”ç”¨å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚
""")

# --- Initialization ---
@st.cache_resource # Cache resources for efficiency
def load_app_resources():
    # This function will now attempt to load both LLM and DB Engine
    # It will return None for resources that fail to initialize
    _llm = get_llm()
    _db_engine = get_db_engine()
    return _llm, _db_engine

llm, db_engine = load_app_resources()

if not llm:
    st.warning("LLM (è¯­è¨€æ¨¡å‹) æœªèƒ½åˆå§‹åŒ–ã€‚è¯·æ£€æŸ¥æ‚¨çš„ API å¯†é’¥é…ç½® (.streamlit/secrets.toml) å’Œé”™è¯¯ä¿¡æ¯ã€‚")
    st.markdown("ç¡®ä¿ `GOOGLE_API_KEY` åœ¨ `.streamlit/secrets.toml` æ–‡ä»¶ä¸­çš„ `[google]` éƒ¨åˆ†ä¸‹æ˜¯æ­£ç¡®çš„ã€‚")
    # We don't stop here, as data loading might still be attempted or user informed.
else:
    st.success("LLM (è¯­è¨€æ¨¡å‹) å·²æˆåŠŸåˆå§‹åŒ–ï¼")

if not db_engine:
    st.error("æ•°æ®åº“å¼•æ“æœªèƒ½åˆå§‹åŒ–ã€‚è¯·æ£€æŸ¥æ‚¨çš„æ•°æ®åº“é…ç½® (.streamlit/secrets.toml) å’Œé”™è¯¯ä¿¡æ¯ã€‚åº”ç”¨å¯èƒ½æ— æ³•åŠ è½½æ•°æ®ã€‚")
    # We don't stop here, user should be informed about PandasAI initialization later if df is None
else:
    st.success("æ•°æ®åº“å¼•æ“å·²æˆåŠŸåˆå§‹åŒ–ï¼")

# --- Data Loading from SQL Server ---
df = None # Initialize df as None
if db_engine: # Proceed only if db_engine was successfully initialized
    st.subheader("æ­£åœ¨ä» SQL Server åŠ è½½ä¼šè®¡åˆ†å½•æ•°æ®...")
    sql_query = """
    SELECT TOP 5000
        ASLIP.SP_DATE,
        ASLIP.SP_NO,
        ASLIP.SP_CHECK, 
        ASPDT.SD_ATNO,
        AACNT.AT_NAME,
        AACNT.AT_DCR AS ACC_DCR, -- Renaming to avoid conflict if SD_DCR is also selected
        ASPDT.SD_AMT,
        ASPDT.SD_DOC,
        ASPDT.SD_DCR AS VOUCHER_DETAIL_SUMMARY, -- Renaming for clarity
        ASLIP.SP_MKMAN
    FROM ASPDT
    INNER JOIN ASLIP ON ASPDT.SD_NO = ASLIP.SP_NO
    INNER JOIN AACNT ON ASPDT.SD_ATNO = AACNT.AT_NO
    WHERE ASLIP.SP_CHECK = 1  -- Assuming 1 means audited/checked
    ORDER BY ASLIP.SP_DATE DESC, ASLIP.SP_NO DESC;
    """
    try:
        with st.spinner("æ­£åœ¨æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢..."):
            df = pd.read_sql(sql_query, db_engine)
        if df.empty:
            st.warning("æŸ¥è¯¢æˆåŠŸï¼Œä½†æœªä»æ•°æ®åº“è¿”å›æ•°æ®ã€‚è¯·æ£€æŸ¥æ‚¨çš„è¡¨ (ASPDT, ASLIP, AACNT) æ˜¯å¦åŒ…å«ç¬¦åˆæ¡ä»¶çš„æ•°æ® (SP_CHECK = 1)ã€‚")
        else:
            st.success(f"æˆåŠŸä»æ•°æ®åº“åŠ è½½äº† {len(df)} æ¡ä¼šè®¡åˆ†å½•ã€‚")
            with st.expander("æŸ¥çœ‹ä»æ•°æ®åº“åŠ è½½çš„æ•°æ®é¢„è§ˆ (å‰10æ¡)", expanded=False):
                st.dataframe(df.head(10))
    except Exception as e:
        st.error(f"ä»æ•°æ®åº“åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        st.info("è¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥ã€è¡¨å (ASPDT, ASLIP, AACNT) å’Œå­—æ®µåæ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ•°æ®åº“æ˜¯å¦å¯è®¿é—®ã€‚")
        df = None # Ensure df is None if loading fails
else:
    st.warning("æ•°æ®åº“å¼•æ“æœªåˆå§‹åŒ–ï¼Œæ— æ³•åŠ è½½æ•°æ®ã€‚è¯·æ£€æŸ¥æ‚¨çš„ secrets.toml æ–‡ä»¶ä¸­çš„æ•°æ®åº“é…ç½®ã€‚")


# --- Initialize PandasAI SmartDataframe ---
smart_df = None
# We proceed with PandasAI setup only if LLM is available AND df is loaded and not empty
if llm and df is not None and not df.empty:
    st.markdown("---")
    st.subheader("AI æ•°æ®åˆ†æåŠ©æ‰‹åˆå§‹åŒ–")
    try:
        # Configuration for PandasAI
        # verbose=True helps in debugging by showing thoughts of the LLM
        # enable_cache=True caches responses for same queries
        # enforce_privacy=True can be used if you want to prevent data from being sent to the LLM
        pandas_ai_config = {
            "llm": llm,
            "verbose": True,
            "enable_cache": True, 
            "enforce_privacy": False, # Set to True if dealing with very sensitive data not to be shared with LLM provider
        }
        smart_df = SmartDataframe(df, config=pandas_ai_config)
        st.success("AI æ•°æ®åˆ†æåŠ©æ‰‹ (PandasAI SmartDataframe) å·²æˆåŠŸåˆå§‹åŒ– (ä½¿ç”¨ä»æ•°æ®åº“åŠ è½½çš„æ•°æ®)ã€‚")
    except Exception as e:
        st.error(f"åˆå§‹åŒ– PandasAI SmartDataframe æ—¶å‡ºé”™: {e}")
        # Do not stop the app, just inform the user. smart_df will remain None.
elif not llm:
    st.error("AI æ•°æ®åˆ†æåŠ©æ‰‹æ— æ³•åˆå§‹åŒ–ï¼Œå› ä¸º LLM (è¯­è¨€æ¨¡å‹) æœªé…ç½®ã€‚")
elif df is None or df.empty:
    st.warning("æ²¡æœ‰ä»æ•°æ®åº“åŠ è½½æ•°æ®ï¼Œæˆ–æ•°æ®ä¸ºç©ºã€‚AI æ•°æ®åˆ†æåŠ©æ‰‹æ— æ³•åˆå§‹åŒ–ã€‚")
    st.markdown("è¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥å’ŒæŸ¥è¯¢é€»è¾‘ã€‚å¦‚æœä½¿ç”¨çš„æ˜¯å ä½ç¬¦å‡­æ®ï¼Œè¯·æ›´æ–°ä¸ºæ‚¨çš„å®é™…æ•°æ®åº“ä¿¡æ¯ã€‚")


# --- User Input and Querying ---
# This section should only be active if smart_df was successfully initialized
st.markdown("---")
st.subheader("ğŸ’¬ å‘ AI æé—®:")
user_question = st.text_input("ä¾‹å¦‚: 'æ€»æ”¶å…¥æ˜¯å¤šå°‘?' æˆ– 'æŒ‰ç±»åˆ«åˆ—å‡ºæ”¯å‡ºæ€»é¢' æˆ– 'å“ªä¸ªåœ°åŒºçš„æ”¶å…¥æœ€é«˜?'")

if st.button("å‘é€æŸ¥è¯¢", type="primary") and user_question and smart_df:
    with st.spinner("AI æ­£åœ¨æ€è€ƒå¹¶æŸ¥è¯¢æ•°æ®... è¯·ç¨å€™..."):
        try:
            # The .chat() method sends the natural language query
            response = smart_df.chat(user_question)

            st.markdown("### ğŸ’¡ AI å›ç­”:")
            if response is None:
                # PandasAI version 1.x and later might return None if the action taken doesn't produce a direct answer (e.g. saving a plot)
                # Check for last_result or other attributes if needed, or rely on verbose logs.
                st.info("AI å·²å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚å¦‚æœé¢„æœŸæœ‰å¯è§è¾“å‡ºä½†æœªæ˜¾ç¤ºï¼Œå®ƒå¯èƒ½å·²æ‰§è¡Œäº†è¯¸å¦‚ç”Ÿæˆå›¾è¡¨ä¹‹ç±»çš„æ“ä½œï¼ˆè¯·æ£€æŸ¥æ˜¯å¦æœ‰å›¾è¡¨æ˜¾ç¤ºæˆ–ä¿å­˜åœ¨å·¥ä½œç›®å½•ä¸­ï¼‰ï¼Œæˆ–è€…å®ƒå¯èƒ½æ— æ³•ç›´æ¥å›ç­”ã€‚")
                # Try to display last generated chart if available
                if hasattr(smart_df, 'last_generated_chart') and smart_df.last_generated_chart:
                    st.image(smart_df.last_generated_chart)
            elif isinstance(response, pd.DataFrame) or isinstance(response, pd.Series):
                st.dataframe(response)
            elif isinstance(response, (str, int, float, list, dict)):
                # Check if it's a plot path (common way pandasai returns plots)
                if isinstance(response, str) and (response.endswith(".png") or response.endswith(".jpg")):
                    st.image(response)
                elif isinstance(response, dict) and response.get("type") == "plot" and "value" in response:
                     st.image(response["value"])
                else:
                    st.write(response)
            else:
                # For any other type of response, try to display it as a string
                st.write(str(response))
                
            # Display last generated code if available (for transparency)
            if hasattr(smart_df, 'last_code_generated') and smart_df.last_code_generated:
                 with st.expander("æŸ¥çœ‹ AI ç”Ÿæˆçš„ä»£ç ", expanded=False):
                    st.code(smart_df.last_code_generated, language='python')

        except Exception as e:
            st.error(f"æ‰§è¡ŒæŸ¥è¯¢æ—¶å‡ºé”™: {e}")
            # Optionally, show last generated code even on error for debugging
            if hasattr(smart_df, 'last_code_generated') and smart_df.last_code_generated:
                 with st.expander("æŸ¥çœ‹ AI ç”Ÿæˆçš„ä»£ç  (å‡ºé”™å‰)", expanded=False):
                    st.code(smart_df.last_code_generated, language='python')

elif st.button("å‘é€æŸ¥è¯¢", type="primary") and not user_question:
    st.warning("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚")

st.markdown("---")
st.info("""
**å…³äºæ­¤é¡µé¢:**
- æ­¤é¡µé¢ä½¿ç”¨ PandasAI è¿æ¥åˆ°æ‚¨çš„ SQL Server æ•°æ®åº“ï¼Œå…è®¸æ‚¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¼šè®¡æ•°æ®ã€‚
- æ•°æ®é€šè¿‡ `app.core.db_connector.py` ä¸­çš„ `get_db_engine()` å‡½æ•°ä» SQL Server åŠ è½½ã€‚
- ä½¿ç”¨çš„è¡¨åŒ…æ‹¬ `ASPDT`, `ASLIP`, å’Œ `AACNT`ã€‚æŸ¥è¯¢è·å–æœ€è¿‘5000æ¡å·²å®¡æ ¸çš„ä¼šè®¡åˆ†å½•ã€‚
- API å¯†é’¥ (ç”¨äº LLM) å’Œæ•°æ®åº“å‡­æ®é€šè¿‡ `.streamlit/secrets.toml` æ–‡ä»¶å®‰å…¨ç®¡ç†ã€‚
- LLM (è¯­è¨€æ¨¡å‹) é€šè¿‡ `app.core.llm_config.py` é…ç½®ã€‚
""", icon="â„¹ï¸")

# To run this app:
# 1. Ensure all dependencies are installed:
#    pip install streamlit pandas pandasai google-generativeai pyodbc SQLAlchemy
# 2. Configure `.streamlit/secrets.toml` with your GOOGLE_API_KEY and actual SQL Server database credentials.
# 3. Run Streamlit: e.g., `streamlit run Home.py` (if you have a main Home page) or `streamlit run pages/1_Chat_with_Data.py`
```
